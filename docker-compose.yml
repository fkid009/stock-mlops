version: '3.8'

services:
  # FastAPI Backend
  api:
    build:
      context: .
      dockerfile: api/Dockerfile
    container_name: stock-api
    ports:
      - "8000:8000"
    environment:
      - APP_ENV=production
      - DEBUG=false
      - DATABASE_URL=sqlite:///./data/stock.db
      - MLFLOW_TRACKING_URI=http://mlflow:5000
      - STOCK_SYMBOLS=${STOCK_SYMBOLS:-AAPL,GOOGL,MSFT}
    volumes:
      - ./data:/app/data
      - ./configs:/app/configs
    depends_on:
      - mlflow
    restart: unless-stopped
    networks:
      - stock-network

  # MLflow Tracking Server
  mlflow:
    image: ghcr.io/mlflow/mlflow:v2.9.0
    container_name: stock-mlflow
    ports:
      - "5000:5000"
    environment:
      - MLFLOW_BACKEND_STORE_URI=sqlite:///mlflow/mlflow.db
      - MLFLOW_DEFAULT_ARTIFACT_ROOT=/mlflow/artifacts
    volumes:
      - mlflow-data:/mlflow
    command: >
      mlflow server
      --host 0.0.0.0
      --port 5000
      --backend-store-uri sqlite:///mlflow/mlflow.db
      --default-artifact-root /mlflow/artifacts
      --serve-artifacts
      --artifacts-destination /mlflow/artifacts
    restart: unless-stopped
    networks:
      - stock-network

  # Airflow Webserver
  airflow-webserver:
    build:
      context: .
      dockerfile: airflow/Dockerfile
    container_name: stock-airflow-webserver
    ports:
      - "8080:8080"
    environment:
      - AIRFLOW__CORE__EXECUTOR=SequentialExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=sqlite:////opt/airflow/airflow.db
      - AIRFLOW__CORE__FERNET_KEY=${AIRFLOW_FERNET_KEY:-}
      - AIRFLOW__CORE__LOAD_EXAMPLES=false
      - AIRFLOW__WEBSERVER__SECRET_KEY=${AIRFLOW_SECRET_KEY:-stock-mlops-secret}
      - MLFLOW_TRACKING_URI=http://mlflow:5000
      - MLFLOW_HTTP_REQUEST_TIMEOUT=600
      - DATABASE_URL=sqlite:////opt/airflow/data/stock.db
      - STOCK_SYMBOLS=${STOCK_SYMBOLS:-AAPL,GOOGL,MSFT}
      - PYTHONPATH=/opt/airflow
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./src:/opt/airflow/src
      - ./configs:/opt/airflow/configs
      - ./data:/opt/airflow/data
      - airflow-logs:/opt/airflow/logs
      - airflow-db:/opt/airflow
    command: webserver
    depends_on:
      - airflow-init
      - mlflow
    restart: unless-stopped
    networks:
      - stock-network

  # Airflow Scheduler
  airflow-scheduler:
    build:
      context: .
      dockerfile: airflow/Dockerfile
    container_name: stock-airflow-scheduler
    environment:
      - AIRFLOW__CORE__EXECUTOR=SequentialExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=sqlite:////opt/airflow/airflow.db
      - AIRFLOW__CORE__FERNET_KEY=${AIRFLOW_FERNET_KEY:-}
      - AIRFLOW__CORE__LOAD_EXAMPLES=false
      - MLFLOW_TRACKING_URI=http://mlflow:5000
      - MLFLOW_HTTP_REQUEST_TIMEOUT=600
      - DATABASE_URL=sqlite:////opt/airflow/data/stock.db
      - STOCK_SYMBOLS=${STOCK_SYMBOLS:-AAPL,GOOGL,MSFT}
      - PYTHONPATH=/opt/airflow
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./src:/opt/airflow/src
      - ./configs:/opt/airflow/configs
      - ./data:/opt/airflow/data
      - airflow-logs:/opt/airflow/logs
      - airflow-db:/opt/airflow
    command: scheduler
    depends_on:
      - airflow-init
      - mlflow
    restart: unless-stopped
    networks:
      - stock-network

  # Airflow Init (one-time setup)
  airflow-init:
    build:
      context: .
      dockerfile: airflow/Dockerfile
    container_name: stock-airflow-init
    environment:
      - AIRFLOW__CORE__EXECUTOR=SequentialExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=sqlite:////opt/airflow/airflow.db
      - AIRFLOW__CORE__LOAD_EXAMPLES=false
    volumes:
      - airflow-logs:/opt/airflow/logs
      - airflow-db:/opt/airflow
    entrypoint: /bin/bash
    command:
      - -c
      - |
        airflow db migrate &&
        airflow users create --username admin --password admin --firstname Admin --lastname User --role Admin --email admin@example.com || true
    networks:
      - stock-network

  # Next.js Frontend (production build)
  web:
    build:
      context: ./web
      dockerfile: Dockerfile
    container_name: stock-web
    ports:
      - "3000:3000"
    environment:
      - NODE_ENV=production
      - NEXT_PUBLIC_API_URL=http://api:8000
    depends_on:
      - api
    restart: unless-stopped
    networks:
      - stock-network

volumes:
  mlflow-data:
  airflow-logs:
  airflow-db:

networks:
  stock-network:
    driver: bridge
